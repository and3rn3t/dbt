{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc264429",
   "metadata": {},
   "source": [
    "# üìà Time Series Analysis: NYC School Performance Trends\n",
    "\n",
    "**Objective:** Analyze how school performance has changed over time\n",
    "\n",
    "**Created:** October 6, 2025\n",
    "\n",
    "## What We'll Do:\n",
    "1. Fetch historical SAT score data from NYC Open Data\n",
    "2. Analyze trends over multiple years\n",
    "3. Identify schools with improving/declining performance\n",
    "4. Examine borough-level trends\n",
    "5. Forecast future performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from scripts.utils import load_csv, save_csv\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")\n",
    "print(f\"üìÅ Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb64c3",
   "metadata": {},
   "source": [
    "## 1. Load Current Data\n",
    "\n",
    "First, let's load the most recent SAT data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current year data\n",
    "try:\n",
    "    current_data = load_csv(\"zt9s-n5aj_20251006_114228.csv\")\n",
    "    print(f\"‚úÖ Loaded current data: {len(current_data)} schools\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Current data file not found. Using processed data.\")\n",
    "    current_data = load_csv(\"nyc_education_analyzed.csv\", subfolder=\"processed\")\n",
    "\n",
    "# Convert SAT scores to numeric\n",
    "for col in ['mathematics_mean', 'critical_reading_mean', 'writing_mean', 'number_of_test_takers']:\n",
    "    if col in current_data.columns:\n",
    "        current_data[col] = pd.to_numeric(current_data[col], errors='coerce')\n",
    "\n",
    "# Calculate total score\n",
    "current_data['total_score'] = (\n",
    "    current_data['mathematics_mean'] + \n",
    "    current_data['critical_reading_mean'] + \n",
    "    current_data['writing_mean']\n",
    ")\n",
    "\n",
    "# Extract or add year\n",
    "current_data['year'] = 2024  # Most recent year in dataset\n",
    "\n",
    "print(f\"\\nData shape: {current_data.shape}\")\n",
    "print(f\"\\nSample data:\")\n",
    "current_data[['dbn', 'school_name', 'total_score', 'year']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811190b7",
   "metadata": {},
   "source": [
    "## 2. Fetch Historical Data (Optional)\n",
    "\n",
    "To do true time series analysis, we would fetch historical data from NYC Open Data.\n",
    "\n",
    "**Note:** For this example, we'll simulate historical data. In production, you would:\n",
    "```python\n",
    "# Fetch data for multiple years\n",
    "!python ../scripts/fetch_data_gov.py zt9s-n5aj --domain data.cityofnewyork.us --limit 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc55824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for other SAT data files in raw directory\n",
    "data_dir = PROJECT_ROOT / 'data' / 'raw'\n",
    "sat_files = list(data_dir.glob('zt9s-n5aj*.csv'))\n",
    "\n",
    "print(f\"Found {len(sat_files)} SAT data file(s):\")\n",
    "for f in sat_files:\n",
    "    print(f\"  ‚Ä¢ {f.name}\")\n",
    "\n",
    "# If we only have one file, simulate historical data for demonstration\n",
    "if len(sat_files) <= 1:\n",
    "    print(\"\\nüìù Simulating historical data for demonstration...\")\n",
    "    \n",
    "    # Create simulated data for 5 previous years\n",
    "    years = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "    historical_dfs = []\n",
    "    \n",
    "    for year in years:\n",
    "        df_year = current_data.copy()\n",
    "        df_year['year'] = year\n",
    "        \n",
    "        # Simulate score changes over time (random walk with slight upward trend)\n",
    "        if year < 2024:\n",
    "            years_diff = 2024 - year\n",
    "            # Add random variation and slight trend\n",
    "            trend = np.random.normal(0, 10, len(df_year))\n",
    "            year_effect = np.random.normal(-years_diff * 2, 15, len(df_year))  # Slight downward trend in past\n",
    "            \n",
    "            df_year['mathematics_mean'] = np.clip(df_year['mathematics_mean'] + year_effect + trend, 200, 800)\n",
    "            df_year['critical_reading_mean'] = np.clip(df_year['critical_reading_mean'] + year_effect + trend, 200, 800)\n",
    "            df_year['writing_mean'] = np.clip(df_year['writing_mean'] + year_effect + trend, 200, 800)\n",
    "            df_year['total_score'] = df_year['mathematics_mean'] + df_year['critical_reading_mean'] + df_year['writing_mean']\n",
    "        \n",
    "        historical_dfs.append(df_year)\n",
    "    \n",
    "    # Combine all years\n",
    "    time_series_df = pd.concat(historical_dfs, ignore_index=True)\n",
    "    \n",
    "    print(f\"‚úÖ Created simulated time series data: {len(time_series_df)} records across {len(years)} years\")\n",
    "else:\n",
    "    # Load multiple files if available\n",
    "    print(\"\\nüìä Loading multiple historical files...\")\n",
    "    historical_dfs = []\n",
    "    for f in sat_files:\n",
    "        df = pd.read_csv(f)\n",
    "        # Try to extract year from filename or data\n",
    "        historical_dfs.append(df)\n",
    "    time_series_df = pd.concat(historical_dfs, ignore_index=True)\n",
    "\n",
    "print(f\"\\nTime series shape: {time_series_df.shape}\")\n",
    "print(f\"Years in dataset: {sorted(time_series_df['year'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ca017",
   "metadata": {},
   "source": [
    "## 3. Overall Performance Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate yearly averages\n",
    "yearly_avg = time_series_df.groupby('year').agg({\n",
    "    'total_score': ['mean', 'median', 'std'],\n",
    "    'mathematics_mean': 'mean',\n",
    "    'critical_reading_mean': 'mean',\n",
    "    'writing_mean': 'mean',\n",
    "    'number_of_test_takers': 'sum'\n",
    "}).round(1)\n",
    "\n",
    "print(\"üìä NYC Average SAT Scores Over Time\\n\" + \"=\"*70)\n",
    "print(yearly_avg)\n",
    "\n",
    "# Create interactive plot\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Average Total SAT Score', 'SAT Sections Over Time', \n",
    "                    'Total Test Takers', 'Score Variability (Std Dev)'),\n",
    "    specs=[[{'secondary_y': False}, {'secondary_y': False}],\n",
    "           [{'secondary_y': False}, {'secondary_y': False}]]\n",
    ")\n",
    "\n",
    "years = sorted(time_series_df['year'].unique())\n",
    "yearly_avg_flat = time_series_df.groupby('year')['total_score'].mean()\n",
    "\n",
    "# Plot 1: Total score trend\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=years, y=yearly_avg_flat.values, mode='lines+markers', \n",
    "               name='Avg Total SAT', line=dict(color='steelblue', width=3)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Individual sections\n",
    "sections = {\n",
    "    'Math': time_series_df.groupby('year')['mathematics_mean'].mean(),\n",
    "    'Reading': time_series_df.groupby('year')['critical_reading_mean'].mean(),\n",
    "    'Writing': time_series_df.groupby('year')['writing_mean'].mean()\n",
    "}\n",
    "colors = {'Math': 'green', 'Reading': 'purple', 'Writing': 'orange'}\n",
    "\n",
    "for section, data in sections.items():\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=years, y=data.values, mode='lines+markers', \n",
    "                   name=section, line=dict(color=colors[section])),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot 3: Test takers\n",
    "total_takers = time_series_df.groupby('year')['number_of_test_takers'].sum()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=years, y=total_takers.values, name='Total Test Takers', marker_color='coral'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Variability\n",
    "std_dev = time_series_df.groupby('year')['total_score'].std()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=years, y=std_dev.values, mode='lines+markers', \n",
    "               name='Std Dev', line=dict(color='red', width=2)),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, showlegend=True, title_text=\"NYC SAT Performance Trends Over Time\")\n",
    "fig.update_xaxes(title_text=\"Year\")\n",
    "fig.show()\n",
    "\n",
    "# Calculate change\n",
    "if len(years) > 1:\n",
    "    first_year_avg = yearly_avg_flat.iloc[0]\n",
    "    last_year_avg = yearly_avg_flat.iloc[-1]\n",
    "    total_change = last_year_avg - first_year_avg\n",
    "    pct_change = (total_change / first_year_avg) * 100\n",
    "    \n",
    "    print(f\"\\nüìà Overall Trend ({years[0]} to {years[-1]}):\")\n",
    "    print(f\"  ‚Ä¢ Starting average: {first_year_avg:.1f}\")\n",
    "    print(f\"  ‚Ä¢ Ending average: {last_year_avg:.1f}\")\n",
    "    print(f\"  ‚Ä¢ Total change: {total_change:+.1f} points ({pct_change:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba04315",
   "metadata": {},
   "source": [
    "## 4. Borough-Level Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c36360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add borough mapping if not present\n",
    "borough_names = {'M': 'Manhattan', 'X': 'Bronx', 'K': 'Brooklyn', 'Q': 'Queens', 'R': 'Staten Island'}\n",
    "\n",
    "if 'borough_name' not in time_series_df.columns and 'boro' in time_series_df.columns:\n",
    "    time_series_df['borough_name'] = time_series_df['boro'].map(borough_names)\n",
    "elif 'borough_name' not in time_series_df.columns:\n",
    "    time_series_df['borough_name'] = time_series_df['dbn'].str[2].map(borough_names)\n",
    "\n",
    "# Calculate borough trends\n",
    "borough_trends = time_series_df.groupby(['year', 'borough_name'])['total_score'].mean().reset_index()\n",
    "\n",
    "# Plot borough trends\n",
    "fig = px.line(\n",
    "    borough_trends,\n",
    "    x='year',\n",
    "    y='total_score',\n",
    "    color='borough_name',\n",
    "    markers=True,\n",
    "    title='Average SAT Scores by Borough Over Time',\n",
    "    labels={'total_score': 'Average SAT Score', 'year': 'Year', 'borough_name': 'Borough'},\n",
    "    line_shape='spline'\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, hovermode='x unified')\n",
    "fig.show()\n",
    "\n",
    "# Calculate borough growth rates\n",
    "print(\"\\nüóΩ Borough Performance Changes\\n\" + \"=\"*70)\n",
    "\n",
    "for borough in borough_trends['borough_name'].unique():\n",
    "    if pd.notna(borough):\n",
    "        borough_data = borough_trends[borough_trends['borough_name'] == borough].sort_values('year')\n",
    "        if len(borough_data) > 1:\n",
    "            first_score = borough_data.iloc[0]['total_score']\n",
    "            last_score = borough_data.iloc[-1]['total_score']\n",
    "            change = last_score - first_score\n",
    "            pct_change = (change / first_score) * 100\n",
    "            \n",
    "            emoji = \"üìà\" if change > 0 else \"üìâ\" if change < 0 else \"‚û°Ô∏è\"\n",
    "            print(f\"{emoji} {borough:15} {first_score:6.1f} ‚Üí {last_score:6.1f} ({change:+6.1f}, {pct_change:+5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ce03d",
   "metadata": {},
   "source": [
    "## 5. Individual School Trends\n",
    "\n",
    "Identify schools with the most improvement and decline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate change for each school\n",
    "school_first_last = time_series_df.groupby('dbn').agg({\n",
    "    'school_name': 'first',\n",
    "    'total_score': ['first', 'last'],\n",
    "    'year': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "school_first_last.columns = ['dbn', 'school_name', 'first_score', 'last_score', 'first_year', 'last_year']\n",
    "school_first_last['change'] = school_first_last['last_score'] - school_first_last['first_score']\n",
    "school_first_last['pct_change'] = (school_first_last['change'] / school_first_last['first_score']) * 100\n",
    "\n",
    "# Remove schools with no change (only one year of data)\n",
    "school_changes = school_first_last[school_first_last['first_year'] != school_first_last['last_year']].copy()\n",
    "\n",
    "print(\"üèÜ Top 10 Most Improved Schools\\n\" + \"=\"*70)\n",
    "top_improvers = school_changes.nlargest(10, 'change')[['school_name', 'first_score', 'last_score', 'change', 'pct_change']]\n",
    "print(top_improvers.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìâ Top 10 Declining Schools\\n\" + \"=\"*70)\n",
    "top_decliners = school_changes.nsmallest(10, 'change')[['school_name', 'first_score', 'last_score', 'change', 'pct_change']]\n",
    "print(top_decliners.to_string(index=False))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Distribution of changes\n",
    "axes[0].hist(school_changes['change'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Change in SAT Score')\n",
    "axes[0].set_ylabel('Number of Schools')\n",
    "axes[0].set_title('Distribution of Score Changes')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Scatter: first vs last scores\n",
    "axes[1].scatter(school_changes['first_score'], school_changes['last_score'], alpha=0.5)\n",
    "axes[1].plot([800, 2400], [800, 2400], 'r--', label='No Change')\n",
    "axes[1].set_xlabel('First Year Score')\n",
    "axes[1].set_ylabel('Last Year Score')\n",
    "axes[1].set_title('School Performance: First vs Last Year')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'data' / 'processed' / 'school_trends_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "improving = (school_changes['change'] > 0).sum()\n",
    "declining = (school_changes['change'] < 0).sum()\n",
    "stable = (school_changes['change'] == 0).sum()\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"  ‚Ä¢ Improving schools: {improving} ({improving/len(school_changes)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Declining schools: {declining} ({declining/len(school_changes)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Stable schools: {stable} ({stable/len(school_changes)*100:.1f}%)\")\n",
    "print(f\"  ‚Ä¢ Average change: {school_changes['change'].mean():.1f} points\")\n",
    "print(f\"  ‚Ä¢ Median change: {school_changes['change'].median():.1f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1994bf7",
   "metadata": {},
   "source": [
    "## 6. Year-over-Year Growth Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year-over-year changes\n",
    "time_series_sorted = time_series_df.sort_values(['dbn', 'year'])\n",
    "time_series_sorted['prev_year_score'] = time_series_sorted.groupby('dbn')['total_score'].shift(1)\n",
    "time_series_sorted['yoy_change'] = time_series_sorted['total_score'] - time_series_sorted['prev_year_score']\n",
    "time_series_sorted['yoy_pct'] = (time_series_sorted['yoy_change'] / time_series_sorted['prev_year_score']) * 100\n",
    "\n",
    "# Aggregate by year\n",
    "yoy_summary = time_series_sorted.groupby('year').agg({\n",
    "    'yoy_change': ['mean', 'median', 'std'],\n",
    "    'yoy_pct': ['mean', 'median']\n",
    "}).round(2)\n",
    "\n",
    "print(\"üìÖ Year-over-Year Changes\\n\" + \"=\"*70)\n",
    "print(yoy_summary)\n",
    "\n",
    "# Plot YoY changes\n",
    "yoy_by_year = time_series_sorted.groupby('year')['yoy_change'].mean().dropna()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=yoy_by_year.index,\n",
    "    y=yoy_by_year.values,\n",
    "    marker_color=['green' if x > 0 else 'red' for x in yoy_by_year.values],\n",
    "    text=[f\"{x:+.1f}\" for x in yoy_by_year.values],\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Average Year-over-Year Change in SAT Scores',\n",
    "    xaxis_title='Year',\n",
    "    yaxis_title='Average Change (points)',\n",
    "    height=500\n",
    ")\n",
    "fig.add_hline(y=0, line_dash='dash', line_color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06804f64",
   "metadata": {},
   "source": [
    "## 7. Volatility Analysis\n",
    "\n",
    "Which schools have the most consistent vs volatile performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc8078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard deviation for each school across years\n",
    "school_volatility = time_series_df.groupby('dbn').agg({\n",
    "    'school_name': 'first',\n",
    "    'total_score': ['mean', 'std', 'count'],\n",
    "    'borough_name': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "school_volatility.columns = ['dbn', 'school_name', 'avg_score', 'std_dev', 'years_count', 'borough']\n",
    "\n",
    "# Only include schools with data for multiple years\n",
    "school_volatility = school_volatility[school_volatility['years_count'] > 1]\n",
    "\n",
    "# Calculate coefficient of variation (CV)\n",
    "school_volatility['cv'] = (school_volatility['std_dev'] / school_volatility['avg_score']) * 100\n",
    "\n",
    "print(\"üéØ Most Consistent Schools (Low Volatility)\\n\" + \"=\"*70)\n",
    "consistent = school_volatility.nsmallest(10, 'std_dev')[['school_name', 'avg_score', 'std_dev', 'cv']]\n",
    "print(consistent.to_string(index=False))\n",
    "\n",
    "print(\"\\nüé¢ Most Volatile Schools\\n\" + \"=\"*70)\n",
    "volatile = school_volatility.nlargest(10, 'std_dev')[['school_name', 'avg_score', 'std_dev', 'cv']]\n",
    "print(volatile.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig = px.scatter(\n",
    "    school_volatility,\n",
    "    x='avg_score',\n",
    "    y='std_dev',\n",
    "    color='borough',\n",
    "    hover_data=['school_name'],\n",
    "    title='School Performance: Average vs Volatility',\n",
    "    labels={'avg_score': 'Average SAT Score', 'std_dev': 'Standard Deviation (Volatility)', 'borough': 'Borough'},\n",
    "    size='std_dev',\n",
    "    size_max=15\n",
    ")\n",
    "fig.update_layout(height=600)\n",
    "fig.show()\n",
    "\n",
    "# Borough volatility comparison\n",
    "if 'borough' in school_volatility.columns:\n",
    "    borough_vol = school_volatility.groupby('borough')['std_dev'].mean().sort_values(ascending=False)\n",
    "    print(\"\\nüìä Average Volatility by Borough:\")\n",
    "    for borough, vol in borough_vol.items():\n",
    "        if pd.notna(borough):\n",
    "            print(f\"  ‚Ä¢ {borough:15} {vol:.1f} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99331314",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0684fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trend analysis results\n",
    "if len(school_changes) > 0:\n",
    "    save_csv(school_changes, 'school_trends_summary.csv', subfolder='processed', index=False)\n",
    "    print(\"‚úÖ Saved: school_trends_summary.csv\")\n",
    "\n",
    "if len(school_volatility) > 0:\n",
    "    save_csv(school_volatility, 'school_volatility_analysis.csv', subfolder='processed', index=False)\n",
    "    print(\"‚úÖ Saved: school_volatility_analysis.csv\")\n",
    "\n",
    "# Save borough trends\n",
    "save_csv(borough_trends, 'borough_trends.csv', subfolder='processed', index=False)\n",
    "print(\"‚úÖ Saved: borough_trends.csv\")\n",
    "\n",
    "print(\"\\n‚úÖ Time series analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53243c04",
   "metadata": {},
   "source": [
    "## 9. Key Insights & Next Steps\n",
    "\n",
    "### üìä Key Findings:\n",
    "- Overall trend in NYC SAT performance\n",
    "- Borough-level performance changes\n",
    "- Individual schools showing improvement or decline\n",
    "- Performance volatility patterns\n",
    "\n",
    "### üîÆ Forecasting (Optional Next Step):\n",
    "To predict future performance, you could:\n",
    "1. Use statistical methods (ARIMA, Prophet)\n",
    "2. Apply machine learning regression\n",
    "3. Build ensemble models\n",
    "\n",
    "### üìà Further Analysis:\n",
    "1. **Seasonal patterns**: If you have within-year data\n",
    "2. **External factors**: Correlate with policy changes, funding, etc.\n",
    "3. **Intervention analysis**: Measure impact of specific programs\n",
    "4. **Cohort analysis**: Track specific student groups over time"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
